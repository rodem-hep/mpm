model_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${paths.full_path}/checkpoints
  filename: best_{epoch:03d}
  monitor: valid/total_loss
  mode: min
  # every_n_epochs: 1
  save_last: True
  auto_insert_metric_name: False

early_stopping:
  _target_: pytorch_lightning.callbacks.EarlyStopping
  monitor: valid/total_loss
  mode: min
  patience: 5

lr_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: step
