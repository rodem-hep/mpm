# @package _global_

# Order indicates overwriting
defaults:
  - override /datamodule: rodem.yaml
  - override /model: fine_tune.yaml
  - override /callbacks: early_stop.yaml

trainer:
  max_epochs: 100

callbacks:
  backbone_fine_tune:
    _target_: src.optimizers.fine_tuning.FeatureExtractorFreezeUnfreeze
    unfreeze_at_epoch: 2

datamodule:
  preproc_fn:
    _target_: src.datamodules.preprocessing.PreProccessGraphs
    n_csts: 64
    del_r_edges: 0
    edge_coords: []
    csts_coords: 
      - del_eta
      - del_phi
      - log_squash_pt
    high_coords: []
    transformation_list: []
    transformation_prob: []


  train_set:
    _target_: src.datamodules.rodem.RODEMMappable
    processes: [QCD, ttbar]
    n_start: 0
    n_files: 1
    n_samples: 1_000

  valid_set:
    _target_: src.datamodules.rodem.RODEMMappable
    processes: ${..train_set.processes}
    n_start: 0
    n_samples: 1_000

  loader_kwargs:
    pin_memory: false
    batch_size: 256
    num_workers: 1
    drop_last: False

project_name: fine_tune
network_name: bert_${now:%Y-%m-%d}_${now:%H-%M-%S-%f}
